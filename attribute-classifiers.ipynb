{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b874c08",
   "metadata": {},
   "source": [
    "# Attribute Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01835460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imports needed from pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD,Adam\n",
    "\n",
    "#Some built-in imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "# SKLearn and Skorch\n",
    "from sklearn.datasets import make_classification\n",
    "from skorch import NeuralNet, NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "#Imports from the repository\n",
    "from data_processing import get_weights_matrix, get_tokens\n",
    "import data_processing as dp\n",
    "from privacy_policies_dataset import PrivacyPoliciesDataset as PPD\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21f203",
   "metadata": {},
   "source": [
    "# 1. Declare Attribute to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6125a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_attribute = 'Does or Does Not'\n",
    "current_num_levels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86ce1d",
   "metadata": {},
   "source": [
    "# 2. Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6a7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts(input_path, output_path, dims = 300, read = False):\n",
    "    \"\"\"\n",
    "    \n",
    "    This functions returns two dictionaries that process the fasttext folder and gets the pretrained \n",
    "    embedding vectors.\n",
    "    \n",
    "    Args:\n",
    "        input_path: string, path to the pretrained embeddings\n",
    "        output_path: string, path to save dictionaries extracted from the pretrained embeddings\n",
    "        dims: integer, embeddings dimensionality to use. (Default = 300)\n",
    "        read: boolean, variable that allows us to decide wether to read from pre-processed files or not.\n",
    "    Returns:\n",
    "        word2vector: dictionary, the keys are the words and the values are the embeddings associated with that word.\n",
    "        word2idx: dictionary, the keys are the words and the values are the indexes associated with that word.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def append_from_file(words, word2idx, vectors, idx, input_path):\n",
    "        \n",
    "        with open(input_path, encoding=\"utf8\") as fast_text_file:\n",
    "\n",
    "            for line in fast_text_file:\n",
    "\n",
    "                split_line = line.split()\n",
    "\n",
    "                word = split_line[0]\n",
    "\n",
    "                words.append(word)\n",
    "\n",
    "                word2idx[word] = idx\n",
    "\n",
    "                vector = np.array(split_line[1:]).astype(float)\n",
    "\n",
    "                vectors.append(vector)\n",
    "                \n",
    "                idx += 1\n",
    "                \n",
    "        return words, word2idx, vectors, idx\n",
    "    \n",
    "\n",
    "    word2vector_path = \"word2vector_\" + str(dims) + \".pkl\"\n",
    "\n",
    "    word2vector_path = join(output_path, word2vector_path)\n",
    "\n",
    "    word2idx_path = \"word2idx_\" + str(dims) + \".pkl\"\n",
    "\n",
    "    word2idx_path = join(output_path, word2idx_path)\n",
    "    \n",
    "    if isfile(word2vector_path) and isfile(word2idx_path) and read:\n",
    "        \n",
    "        print(\"Loading from file {}\".format(word2vector_path))\n",
    "\n",
    "        with open(word2vector_path,\"rb\") as word2vector_file:\n",
    "        \n",
    "            word2vector = pickle.load(word2vector_file)\n",
    "            \n",
    "        print(\"Loading from file {}\".format(word2idx_path))\n",
    "\n",
    "        with open(word2idx_path,\"rb\") as word2idx_file:\n",
    "        \n",
    "            word2idx = pickle.load(word2idx_file)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        print(\"Processing dataset ...\")\n",
    "\n",
    "        words = [None]\n",
    "\n",
    "        word2idx = {None: 0}\n",
    "\n",
    "        idx = 1\n",
    "\n",
    "        vectors = [np.zeros(dims)]\n",
    "        \n",
    "        words, word2idx, vectors, idx = append_from_file(words, word2idx, vectors, idx, input_path)     \n",
    "                           \n",
    "        word2vector = {w: vectors[word2idx[w]] for w in words}\n",
    "        \n",
    "        with open(word2vector_path,\"wb\") as word2vector_file:\n",
    "        \n",
    "            pickle.dump(word2vector, word2vector_file)\n",
    "        \n",
    "        with open(word2idx_path,\"wb\") as word2idx_file:\n",
    "        \n",
    "            pickle.dump(word2idx, word2idx_file)\n",
    "\n",
    "    return word2vector, word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdd10ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from file ./embeddings/word2vector_300.pkl\n",
      "Loading from file ./embeddings/word2idx_300.pkl\n",
      "Loading from file weights_matrix_300.pkl\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = './embeddings/pretrained_embeddings_300.vec'\n",
    "word2vector, word2idx = get_dicts(pretrained_embeddings, f\"./embeddings/\", 300, read = True)\n",
    "weights_matrix = get_weights_matrix(300, f\"./embeddings/\", oov_random = False, dictionary = word2idx, word2vector = word2vector, read = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974ac98",
   "metadata": {},
   "source": [
    "# Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c75501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Does\n",
      "1. Does Not\n"
     ]
    }
   ],
   "source": [
    "labels_file = open(f\"labels/labels_{current_attribute}.pkl\",\"rb\")\n",
    "\n",
    "labels = pickle.load(labels_file)\n",
    "\n",
    "labels_file.close()\n",
    "\n",
    "target_names = []\n",
    "label_indices = []\n",
    "\n",
    "for label, index in labels.items():\n",
    "    target_names.append(label)\n",
    "    label_indices.append(index)\n",
    "    print(str(index) + '. ' + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ae054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_data_Does or Does Not.pkl are already in agg_data/\n"
     ]
    }
   ],
   "source": [
    "dp.aggregate_data_attribute_level(current_attribute, current_num_levels, read = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efddd827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from processed_data/all_sentence_matrices_Does or Does Not.pkl and processed_data/all_label_matrices_Does or Does Not.pkl\n"
     ]
    }
   ],
   "source": [
    "sentence_matrices_all, labels_matrices_all = dp.process_dataset_attribute_level(labels, word2idx, current_attribute, read = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed488f",
   "metadata": {},
   "source": [
    "We now create an PPD which stands for PrivacyPoliciesDataset containing the training and testing dataset. We will need to split the data in two to get the test training data and the data that will be used for training and validation. The function split_dataset_randomly is spliting the dataset 90/10 by default. It uses a consistent random seed as 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cccd41cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/polisis-replication/privacy_policies_dataset.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels_tensor = tensor(labels_list).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "dataset = PPD(sentence_matrices_all, labels_matrices_all, labels)\n",
    "\n",
    "test_dataset, train_dataset = dataset.split_dataset_randomly(ratio = 0.4, seed=42)\n",
    "\n",
    "test_dataset.pickle_dataset(f\"datasets/test_dataset_{current_attribute}.pkl\")\n",
    "\n",
    "train_dataset.pickle_dataset(f\"datasets/train_dataset_{current_attribute}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0bcda01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of segments: 1824\n",
      "Num of labels: 2183\n",
      "Percentages with respect to number of labels ... \n",
      "0. Does : 1703 (78.01191021530005%)\n",
      "1. Does Not : 480 (21.988089784699955%)\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Num of segments: 1215\n",
      "Num of labels: 1447\n",
      "Percentages with respect to number of labels ... \n",
      "0. Does : 1150 (79.47477539737388%)\n",
      "1. Does Not : 297 (20.525224602626125%)\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_dataset.labels_stats()\n",
    "print(\"-\" * 35 * 3)\n",
    "test_dataset.labels_stats()\n",
    "print(\"-\" * 35 * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56dd0b2",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d5233a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Convolutional Neural Model used for training the models. The total number of kernels that will be used in this\n",
    "    CNN is Co * len(Ks). \n",
    "    \n",
    "    Args:\n",
    "        weights_matrix: numpy.ndarray, the shape of this n-dimensional array must be (words, dims) were words is\n",
    "        the number of words in the vocabulary and dims is the dimensionality of the word embeddings.\n",
    "        Co (number of filters): integer, stands for channels out and it is the number of kernels of the same size that will be used.\n",
    "        Hu: integer, stands for number of hidden units in the hidden layer.\n",
    "        C: integer, number of units in the last layer (number of classes)\n",
    "        Ks: list, list of integers specifying the size of the kernels to be used. \n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings, vocab_size, emb_dim, Co, Hu, C, Ks, dropout, name = 'generic'):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "              \n",
    "        self.num_embeddings = vocab_size\n",
    "        \n",
    "        self.embeddings_dim = emb_dim\n",
    "\n",
    "        self.padding_index = 0\n",
    "        \n",
    "        self.cnn_name = 'cnn_' + str(emb_dim) + '_' + str(Co) + '_' + str(Hu) + '_' + str(C) + '_' + str(Ks) + '_' + name\n",
    "\n",
    "        self.Co = Co\n",
    "        \n",
    "        self.Hu = Hu\n",
    "        \n",
    "        self.C = C\n",
    "        \n",
    "        self.Ks = Ks\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.num_embeddings, self.embeddings_dim, self.padding_index)\n",
    "        self.embedding = self.embedding.from_pretrained(torch.tensor(embeddings).float(), freeze=True)\n",
    "\n",
    "        self.convolutions = nn.ModuleList([nn.Conv2d(1,self.Co,(k, self.embeddings_dim)) for k in self.Ks])\n",
    "        \n",
    "        # activation function for hidden layers =  Rectified Linear Unit\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.drop_out = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.Co * len(self.Ks), self.Hu[0])\n",
    "        \n",
    "        self.linear2 = nn.Linear(self.Hu[-1], self.C)\n",
    "        \n",
    "        # activation function of output layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.double()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        #size(N,1,length) to size(N,1,length,dims)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        #size(N,1,length,dims) to size(N,1,length)\n",
    "        \n",
    "        x = [self.relu(conv(x)).squeeze(3) for conv in self.convolutions]\n",
    "        \n",
    "        #size(N,1,length) to (N, Co * len(Ks))\n",
    "        \n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
    "        \n",
    "        x = torch.cat(x,1)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "399bdba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_data(batch):\n",
    "\n",
    "    def stack_segments(segments, clearance = 2):\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        segments_len = map(len, segments)\n",
    "        max_len = max(segments_len)\n",
    "\n",
    "        segments_list = []\n",
    "\n",
    "        output_len = max_len + clearance * 2\n",
    "\n",
    "        for i, segment in enumerate(segments):\n",
    "\n",
    "            segment_array = np.array(segment)\n",
    "\n",
    "            zeros_to_prepend = int((output_len - len(segment_array))/2)\n",
    "\n",
    "            zeros_to_append = output_len - len(segment_array) - zeros_to_prepend\n",
    "\n",
    "            resized_array = np.append(np.zeros(zeros_to_prepend), segment_array)\n",
    "\n",
    "            resized_array = np.append(resized_array, np.zeros(zeros_to_append))\n",
    "\n",
    "            segments_list.append(torch.tensor(resized_array, dtype = torch.int64, device=torch.device(\"cuda\")))\n",
    "\n",
    "            segments_tensor = torch.stack(segments_list).unsqueeze(1)\n",
    "\n",
    "        return segments_tensor                         \n",
    "\n",
    "    segments = [item[0] for item in batch]\n",
    "\n",
    "    labels = [item[1] for item in batch]\n",
    "\n",
    "    segments_tensor = stack_segments(segments)\n",
    "\n",
    "    labels_tensor = torch.stack(labels)\n",
    "\n",
    "    return [segments_tensor, labels_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d4930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_f1_presence(y_true, y_pred):\n",
    "    y_pred = y_pred > 0.5\n",
    "    return f1_score(y_true, y_pred, average='macro', zero_division='warn')\n",
    "\n",
    "def my_custom_f1_absence(y_true, y_pred):\n",
    "    y_pred = y_pred <= 0.5\n",
    "    return f1_score(y_true < 1, y_pred, average='macro', zero_division='warn')\n",
    "\n",
    "\n",
    "score_presence = make_scorer(my_custom_f1_presence, needs_proba=True)\n",
    "score_absence = make_scorer(my_custom_f1_absence, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef0ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    CNN,\n",
    "    module__embeddings = weights_matrix,\n",
    "    module__vocab_size = weights_matrix.shape[0],\n",
    "    module__emb_dim = weights_matrix.shape[1],\n",
    "    module__Co = 200,\n",
    "    module__Hu = [100],\n",
    "    module__C = current_num_levels,\n",
    "    module__Ks = [3],\n",
    "    module__name = f'{current_attribute}_zeros_60-20-(no-val)_polisis',\n",
    "    module__dropout = 0.5,\n",
    "    max_epochs = 100,\n",
    "    lr = 0.001,\n",
    "    optimizer = SGD,\n",
    "    optimizer__weight_decay = 0,\n",
    "    optimizer__momentum=0.9,\n",
    "    criterion = nn.BCELoss(),\n",
    "    batch_size=40,\n",
    "    # Turn the validation split off once we have the metadata values set\n",
    "    train_split = None,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__collate_fn=collate_data,\n",
    "    iterator_valid__collate_fn=collate_data,\n",
    "    # Turn off verbose\n",
    "#     verbose = 0,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef80c521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6755\u001b[0m  2.9656\n",
      "      2        \u001b[36m0.6198\u001b[0m  1.0048\n",
      "      3        \u001b[36m0.5702\u001b[0m  1.0239\n",
      "      4        \u001b[36m0.5242\u001b[0m  0.9969\n",
      "      5        \u001b[36m0.4828\u001b[0m  1.0006\n",
      "      6        \u001b[36m0.4492\u001b[0m  0.9911\n",
      "      7        \u001b[36m0.4251\u001b[0m  0.9790\n",
      "      8        \u001b[36m0.4091\u001b[0m  0.9761\n",
      "      9        \u001b[36m0.3991\u001b[0m  0.9464\n",
      "     10        \u001b[36m0.3921\u001b[0m  0.9871\n",
      "     11        \u001b[36m0.3871\u001b[0m  1.0151\n",
      "     12        \u001b[36m0.3830\u001b[0m  0.9599\n",
      "     13        \u001b[36m0.3796\u001b[0m  0.9844\n",
      "     14        \u001b[36m0.3765\u001b[0m  0.9935\n",
      "     15        \u001b[36m0.3737\u001b[0m  0.9982\n",
      "     16        \u001b[36m0.3710\u001b[0m  0.9760\n",
      "     17        \u001b[36m0.3684\u001b[0m  0.9703\n",
      "     18        \u001b[36m0.3659\u001b[0m  0.9616\n",
      "     19        \u001b[36m0.3634\u001b[0m  0.9638\n",
      "     20        \u001b[36m0.3609\u001b[0m  0.9654\n",
      "     21        \u001b[36m0.3584\u001b[0m  0.9686\n",
      "     22        \u001b[36m0.3559\u001b[0m  0.9912\n",
      "     23        \u001b[36m0.3533\u001b[0m  0.9813\n",
      "     24        \u001b[36m0.3508\u001b[0m  0.9882\n",
      "     25        \u001b[36m0.3481\u001b[0m  0.9881\n",
      "     26        \u001b[36m0.3455\u001b[0m  0.9583\n",
      "     27        \u001b[36m0.3427\u001b[0m  0.9746\n",
      "     28        \u001b[36m0.3398\u001b[0m  0.9600\n",
      "     29        \u001b[36m0.3368\u001b[0m  0.9834\n",
      "     30        \u001b[36m0.3338\u001b[0m  1.0119\n",
      "     31        \u001b[36m0.3307\u001b[0m  1.0162\n",
      "     32        \u001b[36m0.3276\u001b[0m  0.9873\n",
      "     33        \u001b[36m0.3241\u001b[0m  0.9927\n",
      "     34        \u001b[36m0.3207\u001b[0m  0.9991\n",
      "     35        \u001b[36m0.3172\u001b[0m  0.9980\n",
      "     36        \u001b[36m0.3134\u001b[0m  1.0189\n",
      "     37        \u001b[36m0.3095\u001b[0m  0.9524\n",
      "     38        \u001b[36m0.3057\u001b[0m  0.9643\n",
      "     39        \u001b[36m0.3017\u001b[0m  0.9749\n",
      "     40        \u001b[36m0.2976\u001b[0m  0.9721\n",
      "     41        \u001b[36m0.2934\u001b[0m  0.9900\n",
      "     42        \u001b[36m0.2892\u001b[0m  0.9642\n",
      "     43        \u001b[36m0.2849\u001b[0m  0.9709\n",
      "     44        \u001b[36m0.2805\u001b[0m  0.9578\n",
      "     45        \u001b[36m0.2762\u001b[0m  0.9973\n",
      "     46        \u001b[36m0.2719\u001b[0m  1.0128\n",
      "     47        \u001b[36m0.2676\u001b[0m  1.0259\n",
      "     48        \u001b[36m0.2635\u001b[0m  0.9900\n",
      "     49        \u001b[36m0.2596\u001b[0m  1.0404\n",
      "     50        \u001b[36m0.2557\u001b[0m  1.0639\n",
      "     51        \u001b[36m0.2518\u001b[0m  1.0922\n",
      "     52        \u001b[36m0.2482\u001b[0m  1.0539\n",
      "     53        \u001b[36m0.2448\u001b[0m  1.0621\n",
      "     54        \u001b[36m0.2416\u001b[0m  1.2522\n",
      "     55        \u001b[36m0.2386\u001b[0m  2.0321\n",
      "     56        \u001b[36m0.2358\u001b[0m  2.0251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.net.NeuralNet'>[initialized](\n",
       "  module_=CNN(\n",
       "    (embedding): Embedding(133865, 300)\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Conv2d(1, 200, kernel_size=(3, 300), stride=(1, 1))\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (drop_out): Dropout(p=0.5, inplace=False)\n",
       "    (linear1): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(train_dataset.segments_array, train_dataset.labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "33f4da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5523\u001b[0m  0.9048\n",
      "      2        \u001b[36m0.3810\u001b[0m  0.7983\n",
      "      3        \u001b[36m0.3608\u001b[0m  0.8114\n",
      "      4        \u001b[36m0.3456\u001b[0m  0.8006\n",
      "      5        \u001b[36m0.3295\u001b[0m  0.8193\n",
      "      6        \u001b[36m0.3107\u001b[0m  0.8155\n",
      "      7        \u001b[36m0.2882\u001b[0m  0.8179\n",
      "      8        \u001b[36m0.2662\u001b[0m  0.8083\n",
      "      9        \u001b[36m0.2456\u001b[0m  0.8491\n",
      "     10        \u001b[36m0.2269\u001b[0m  0.8108\n",
      "     11        \u001b[36m0.2132\u001b[0m  0.8118\n",
      "     12        \u001b[36m0.2020\u001b[0m  0.8220\n",
      "     13        \u001b[36m0.1916\u001b[0m  0.8069\n",
      "     14        \u001b[36m0.1819\u001b[0m  0.7729\n",
      "     15        \u001b[36m0.1733\u001b[0m  0.8075\n",
      "     16        \u001b[36m0.1659\u001b[0m  0.7935\n",
      "     17        \u001b[36m0.1570\u001b[0m  0.8034\n",
      "     18        \u001b[36m0.1511\u001b[0m  0.8369\n",
      "     19        \u001b[36m0.1440\u001b[0m  0.8010\n",
      "     20        \u001b[36m0.1354\u001b[0m  0.8029\n",
      "     21        \u001b[36m0.1297\u001b[0m  0.8134\n",
      "     22        \u001b[36m0.1244\u001b[0m  0.8190\n",
      "     23        \u001b[36m0.1212\u001b[0m  0.8000\n",
      "     24        \u001b[36m0.1174\u001b[0m  0.8120\n",
      "     25        \u001b[36m0.1128\u001b[0m  0.8027\n",
      "     26        \u001b[36m0.1075\u001b[0m  0.8145\n",
      "     27        \u001b[36m0.1047\u001b[0m  0.8084\n",
      "     28        \u001b[36m0.1019\u001b[0m  0.8139\n",
      "     29        0.1026  0.8233\n",
      "     30        \u001b[36m0.0987\u001b[0m  0.7905\n",
      "     31        \u001b[36m0.0960\u001b[0m  0.8090\n",
      "     32        \u001b[36m0.0949\u001b[0m  0.8145\n",
      "     33        \u001b[36m0.0925\u001b[0m  0.7923\n",
      "     34        \u001b[36m0.0919\u001b[0m  0.8280\n",
      "     35        \u001b[36m0.0908\u001b[0m  0.8238\n",
      "     36        \u001b[36m0.0893\u001b[0m  0.8109\n",
      "     37        0.0895  0.8236\n",
      "     38        \u001b[36m0.0883\u001b[0m  0.8288\n",
      "     39        \u001b[36m0.0865\u001b[0m  0.8211\n",
      "     40        \u001b[36m0.0857\u001b[0m  0.8022\n",
      "     41        \u001b[36m0.0838\u001b[0m  0.8202\n",
      "     42        \u001b[36m0.0829\u001b[0m  0.8437\n",
      "     43        0.0834  0.8370\n",
      "     44        0.0862  0.7888\n",
      "     45        \u001b[36m0.0806\u001b[0m  0.8227\n",
      "     46        0.0831  0.8090\n",
      "     47        0.0815  0.8511\n",
      "     48        \u001b[36m0.0792\u001b[0m  0.8036\n",
      "     49        \u001b[36m0.0785\u001b[0m  0.8224\n",
      "     50        0.0830  0.8181\n",
      "     51        \u001b[36m0.0781\u001b[0m  0.8205\n",
      "     52        \u001b[36m0.0779\u001b[0m  0.8192\n",
      "     53        \u001b[36m0.0773\u001b[0m  0.8328\n",
      "     54        \u001b[36m0.0771\u001b[0m  0.7847\n",
      "     55        \u001b[36m0.0766\u001b[0m  0.8222\n",
      "     56        0.0772  0.8233\n",
      "     57        0.0801  0.7996\n",
      "     58        \u001b[36m0.0747\u001b[0m  0.8067\n",
      "     59        0.0757  0.8283\n",
      "     60        0.0759  0.8049\n",
      "     61        0.0771  0.8190\n",
      "     62        \u001b[36m0.0742\u001b[0m  0.8165\n",
      "     63        \u001b[36m0.0732\u001b[0m  0.7870\n",
      "     64        0.0737  0.8214\n",
      "     65        \u001b[36m0.0725\u001b[0m  0.8077\n",
      "     66        0.0739  0.7978\n",
      "     67        \u001b[36m0.0714\u001b[0m  0.8098\n",
      "     68        0.0726  0.8036\n",
      "     69        0.0731  0.8149\n",
      "     70        \u001b[36m0.0713\u001b[0m  0.8169\n",
      "     71        0.0726  0.8170\n",
      "     72        0.0720  0.8171\n",
      "     73        0.0728  0.8065\n",
      "     74        0.0773  0.8072\n",
      "     75        0.0765  0.8011\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5477\u001b[0m  0.8380\n",
      "      2        \u001b[36m0.3982\u001b[0m  0.8296\n",
      "      3        \u001b[36m0.3781\u001b[0m  0.8172\n",
      "      4        \u001b[36m0.3593\u001b[0m  0.8086\n",
      "      5        \u001b[36m0.3386\u001b[0m  0.8295\n",
      "      6        \u001b[36m0.3132\u001b[0m  0.8263\n",
      "      7        \u001b[36m0.2839\u001b[0m  0.8123\n",
      "      8        \u001b[36m0.2553\u001b[0m  0.8450\n",
      "      9        \u001b[36m0.2341\u001b[0m  0.8098\n",
      "     10        \u001b[36m0.2178\u001b[0m  0.8331\n",
      "     11        \u001b[36m0.2072\u001b[0m  0.7661\n",
      "     12        \u001b[36m0.2000\u001b[0m  0.8036\n",
      "     13        \u001b[36m0.1882\u001b[0m  0.8262\n",
      "     14        \u001b[36m0.1794\u001b[0m  0.8243\n",
      "     15        \u001b[36m0.1708\u001b[0m  0.7990\n",
      "     16        \u001b[36m0.1615\u001b[0m  0.8226\n",
      "     17        \u001b[36m0.1553\u001b[0m  0.7797\n",
      "     18        \u001b[36m0.1482\u001b[0m  0.8188\n",
      "     19        \u001b[36m0.1398\u001b[0m  0.8110\n",
      "     20        \u001b[36m0.1334\u001b[0m  0.8283\n",
      "     21        \u001b[36m0.1299\u001b[0m  0.8195\n",
      "     22        \u001b[36m0.1258\u001b[0m  0.8075\n",
      "     23        \u001b[36m0.1191\u001b[0m  0.8026\n",
      "     24        \u001b[36m0.1157\u001b[0m  0.7968\n",
      "     25        \u001b[36m0.1115\u001b[0m  0.8355\n",
      "     26        \u001b[36m0.1107\u001b[0m  0.8159\n",
      "     27        \u001b[36m0.1054\u001b[0m  0.7916\n",
      "     28        \u001b[36m0.1037\u001b[0m  0.7968\n",
      "     29        \u001b[36m0.1013\u001b[0m  0.8161\n",
      "     30        \u001b[36m0.0998\u001b[0m  0.7862\n",
      "     31        \u001b[36m0.0978\u001b[0m  0.7968\n",
      "     32        \u001b[36m0.0968\u001b[0m  0.8055\n",
      "     33        0.0969  0.8112\n",
      "     34        \u001b[36m0.0933\u001b[0m  0.8336\n",
      "     35        \u001b[36m0.0917\u001b[0m  0.8191\n",
      "     36        \u001b[36m0.0904\u001b[0m  0.8092\n",
      "     37        0.0928  0.7831\n",
      "     38        0.0923  0.8354\n",
      "     39        \u001b[36m0.0869\u001b[0m  0.8179\n",
      "     40        \u001b[36m0.0856\u001b[0m  0.8229\n",
      "     41        0.0858  0.8303\n",
      "     42        \u001b[36m0.0855\u001b[0m  0.8478\n",
      "     43        \u001b[36m0.0850\u001b[0m  0.8142\n",
      "     44        \u001b[36m0.0843\u001b[0m  0.8120\n",
      "     45        \u001b[36m0.0837\u001b[0m  0.8130\n",
      "     46        0.0874  0.8282\n",
      "     47        \u001b[36m0.0814\u001b[0m  0.8061\n",
      "     48        0.0827  0.8222\n",
      "     49        \u001b[36m0.0805\u001b[0m  0.7952\n",
      "     50        \u001b[36m0.0803\u001b[0m  0.7974\n",
      "     51        \u001b[36m0.0788\u001b[0m  0.7988\n",
      "     52        0.0809  0.8086\n",
      "     53        \u001b[36m0.0787\u001b[0m  0.8056\n",
      "     54        0.0804  0.8180\n",
      "     55        0.0791  0.8146\n",
      "     56        0.0793  0.8079\n",
      "     57        \u001b[36m0.0780\u001b[0m  0.8251\n",
      "     58        0.0787  0.8150\n",
      "     59        \u001b[36m0.0772\u001b[0m  0.8226\n",
      "     60        \u001b[36m0.0769\u001b[0m  0.8128\n",
      "     61        \u001b[36m0.0766\u001b[0m  0.7891\n",
      "     62        0.0770  0.8152\n",
      "     63        0.0788  0.7830\n",
      "     64        0.0778  0.7905\n",
      "     65        0.0798  0.8329\n",
      "     66        0.0768  0.7992\n",
      "     67        \u001b[36m0.0761\u001b[0m  0.8084\n",
      "     68        \u001b[36m0.0747\u001b[0m  0.8113\n",
      "     69        0.0761  0.7841\n",
      "     70        0.0777  0.8250\n",
      "     71        0.0764  0.8192\n",
      "     72        0.0753  0.8461\n",
      "     73        0.0748  0.8130\n",
      "     74        0.0770  0.8180\n",
      "     75        0.0756  0.7921\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5693\u001b[0m  0.7988\n",
      "      2        \u001b[36m0.3933\u001b[0m  0.8246\n",
      "      3        \u001b[36m0.3698\u001b[0m  0.8152\n",
      "      4        \u001b[36m0.3517\u001b[0m  0.7830\n",
      "      5        \u001b[36m0.3295\u001b[0m  0.7954\n",
      "      6        \u001b[36m0.3024\u001b[0m  0.7867\n",
      "      7        \u001b[36m0.2716\u001b[0m  0.7897\n",
      "      8        \u001b[36m0.2439\u001b[0m  0.8109\n",
      "      9        \u001b[36m0.2235\u001b[0m  0.8050\n",
      "     10        \u001b[36m0.2101\u001b[0m  0.7865\n",
      "     11        \u001b[36m0.1993\u001b[0m  0.7858\n",
      "     12        \u001b[36m0.1892\u001b[0m  0.7826\n",
      "     13        \u001b[36m0.1814\u001b[0m  0.7841\n",
      "     14        \u001b[36m0.1722\u001b[0m  0.7973\n",
      "     15        \u001b[36m0.1640\u001b[0m  0.7766\n",
      "     16        \u001b[36m0.1560\u001b[0m  0.7806\n",
      "     17        \u001b[36m0.1486\u001b[0m  0.7605\n",
      "     18        \u001b[36m0.1417\u001b[0m  0.7810\n",
      "     19        \u001b[36m0.1366\u001b[0m  0.7758\n",
      "     20        \u001b[36m0.1304\u001b[0m  0.7868\n",
      "     21        \u001b[36m0.1248\u001b[0m  0.7798\n",
      "     22        \u001b[36m0.1197\u001b[0m  0.8265\n",
      "     23        \u001b[36m0.1166\u001b[0m  0.8071\n",
      "     24        \u001b[36m0.1119\u001b[0m  0.8257\n",
      "     25        \u001b[36m0.1094\u001b[0m  0.7810\n",
      "     26        \u001b[36m0.1056\u001b[0m  0.7760\n",
      "     27        \u001b[36m0.1038\u001b[0m  0.7818\n",
      "     28        \u001b[36m0.1009\u001b[0m  0.7970\n",
      "     29        \u001b[36m0.0978\u001b[0m  0.7928\n",
      "     30        \u001b[36m0.0962\u001b[0m  0.7930\n",
      "     31        \u001b[36m0.0936\u001b[0m  0.7724\n",
      "     32        \u001b[36m0.0930\u001b[0m  0.8071\n",
      "     33        \u001b[36m0.0924\u001b[0m  0.7973\n",
      "     34        \u001b[36m0.0904\u001b[0m  0.7994\n",
      "     35        \u001b[36m0.0894\u001b[0m  0.7992\n",
      "     36        \u001b[36m0.0879\u001b[0m  0.8176\n",
      "     37        \u001b[36m0.0873\u001b[0m  0.8271\n",
      "     38        \u001b[36m0.0847\u001b[0m  0.8058\n",
      "     39        \u001b[36m0.0841\u001b[0m  0.7713\n",
      "     40        \u001b[36m0.0831\u001b[0m  0.7910\n",
      "     41        \u001b[36m0.0825\u001b[0m  0.7873\n",
      "     42        0.0836  0.8180\n",
      "     43        \u001b[36m0.0808\u001b[0m  0.7824\n",
      "     44        \u001b[36m0.0792\u001b[0m  0.7597\n",
      "     45        \u001b[36m0.0790\u001b[0m  0.7776\n",
      "     46        \u001b[36m0.0783\u001b[0m  0.8163\n",
      "     47        0.0789  0.7879\n",
      "     48        \u001b[36m0.0775\u001b[0m  0.7838\n",
      "     49        \u001b[36m0.0770\u001b[0m  0.7984\n",
      "     50        0.0788  0.7630\n",
      "     51        \u001b[36m0.0770\u001b[0m  0.7875\n",
      "     52        0.0794  0.8012\n",
      "     53        0.0787  0.7473\n",
      "     54        \u001b[36m0.0758\u001b[0m  0.7926\n",
      "     55        0.0760  0.7945\n",
      "     56        \u001b[36m0.0746\u001b[0m  0.7867\n",
      "     57        \u001b[36m0.0727\u001b[0m  0.7898\n",
      "     58        0.0734  0.8007\n",
      "     59        0.0742  0.7738\n",
      "     60        0.0737  0.7648\n",
      "     61        0.0746  0.7606\n",
      "     62        \u001b[36m0.0710\u001b[0m  0.7878\n",
      "     63        0.0735  0.7777\n",
      "     64        0.0812  0.7301\n",
      "     65        0.0744  0.8046\n",
      "     66        0.0729  0.7680\n",
      "     67        0.0724  0.7784\n",
      "     68        0.0734  0.7962\n",
      "     69        0.0730  0.7708\n",
      "     70        0.0736  0.7971\n",
      "     71        0.0723  0.7923\n",
      "     72        \u001b[36m0.0707\u001b[0m  0.8105\n",
      "     73        0.0733  0.7956\n",
      "     74        0.0713  0.7784\n",
      "     75        0.0720  0.7943\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5656\u001b[0m  0.7837\n",
      "      2        \u001b[36m0.3932\u001b[0m  0.7870\n",
      "      3        \u001b[36m0.3686\u001b[0m  0.7862\n",
      "      4        \u001b[36m0.3503\u001b[0m  0.7840\n",
      "      5        \u001b[36m0.3283\u001b[0m  0.7968\n",
      "      6        \u001b[36m0.2985\u001b[0m  0.7841\n",
      "      7        \u001b[36m0.2622\u001b[0m  0.8191\n",
      "      8        \u001b[36m0.2326\u001b[0m  0.8034\n",
      "      9        \u001b[36m0.2140\u001b[0m  0.7882\n",
      "     10        \u001b[36m0.2023\u001b[0m  0.7963\n",
      "     11        \u001b[36m0.1910\u001b[0m  0.7731\n",
      "     12        \u001b[36m0.1822\u001b[0m  0.7912\n",
      "     13        \u001b[36m0.1723\u001b[0m  0.8175\n",
      "     14        \u001b[36m0.1644\u001b[0m  0.7775\n",
      "     15        \u001b[36m0.1550\u001b[0m  0.7865\n",
      "     16        \u001b[36m0.1485\u001b[0m  0.7894\n",
      "     17        \u001b[36m0.1403\u001b[0m  0.7841\n",
      "     18        \u001b[36m0.1339\u001b[0m  0.8148\n",
      "     19        \u001b[36m0.1280\u001b[0m  0.7667\n",
      "     20        \u001b[36m0.1248\u001b[0m  0.7635\n",
      "     21        \u001b[36m0.1192\u001b[0m  0.7873\n",
      "     22        \u001b[36m0.1142\u001b[0m  0.7782\n",
      "     23        \u001b[36m0.1100\u001b[0m  0.8082\n",
      "     24        \u001b[36m0.1072\u001b[0m  0.7810\n",
      "     25        \u001b[36m0.1038\u001b[0m  0.7846\n",
      "     26        \u001b[36m0.1003\u001b[0m  0.7943\n",
      "     27        \u001b[36m0.0983\u001b[0m  0.7768\n",
      "     28        \u001b[36m0.0971\u001b[0m  0.7894\n",
      "     29        0.0980  0.7940\n",
      "     30        \u001b[36m0.0944\u001b[0m  0.7935\n",
      "     31        \u001b[36m0.0916\u001b[0m  0.8044\n",
      "     32        \u001b[36m0.0911\u001b[0m  0.8041\n",
      "     33        \u001b[36m0.0883\u001b[0m  0.8253\n",
      "     34        \u001b[36m0.0882\u001b[0m  0.8120\n",
      "     35        \u001b[36m0.0870\u001b[0m  0.7906\n",
      "     36        \u001b[36m0.0868\u001b[0m  0.7883\n",
      "     37        \u001b[36m0.0866\u001b[0m  0.8201\n",
      "     38        \u001b[36m0.0854\u001b[0m  0.7931\n",
      "     39        \u001b[36m0.0841\u001b[0m  0.8161\n",
      "     40        0.0859  0.8095\n",
      "     41        \u001b[36m0.0815\u001b[0m  0.8007\n",
      "     42        \u001b[36m0.0801\u001b[0m  0.7727\n",
      "     43        0.0803  0.8096\n",
      "     44        \u001b[36m0.0797\u001b[0m  0.7802\n",
      "     45        0.0810  0.8212\n",
      "     46        \u001b[36m0.0780\u001b[0m  0.8119\n",
      "     47        0.0797  0.8042\n",
      "     48        \u001b[36m0.0771\u001b[0m  0.8157\n",
      "     49        \u001b[36m0.0757\u001b[0m  0.7958\n",
      "     50        \u001b[36m0.0751\u001b[0m  0.7849\n",
      "     51        \u001b[36m0.0746\u001b[0m  0.8249\n",
      "     52        \u001b[36m0.0735\u001b[0m  0.8156\n",
      "     53        0.0743  0.8192\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1525/2460638495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'presence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'presence'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore_presence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'absence'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore_absence\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \"\"\"\n\u001b[1;32m   1212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/skorch/net.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_virtual_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/skorch/net.py\u001b[0m in \u001b[0;36m_initialize_module\u001b[0;34m(self, reason)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/skorch/utils.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(X, device)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lr': [0.01, 0.001],\n",
    "    'max_epochs': [75, 100, 200, 300]\n",
    "}\n",
    "gs = RandomizedSearchCV(net, params, refit='presence', cv=5,  scoring={'presence': score_presence,'absence': score_absence})\n",
    "gs.fit(train_dataset.segments_array, train_dataset.labels_tensor)\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_.save_params(f_params=f'trained_models/{current_attribute}/model.pkl',f_optimizer=f'trained_models/{current_attribute}/optimizer.pkl', f_history=f'trained_models/{current_attribute}/history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a58c1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.save_params(f_params=f'trained_models/{current_attribute}/model.pkl',f_optimizer=f'trained_models/{current_attribute}/optimizer.pkl', f_history=f'trained_models/{current_attribute}/history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd96e7",
   "metadata": {},
   "source": [
    "# Evaluate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a6fa58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Trained Model\n",
    "net = NeuralNet(\n",
    "    CNN,\n",
    "    module__embeddings = weights_matrix,\n",
    "    module__vocab_size = weights_matrix.shape[0],\n",
    "    module__emb_dim = weights_matrix.shape[1],\n",
    "    module__Co = 200,\n",
    "    module__Hu = [100],\n",
    "    module__C = current_num_levels,\n",
    "    module__Ks = [3],\n",
    "    module__name = f'{current_attribute}_zeros_60-20-(no-val)_polisis',\n",
    "    module__dropout = 0.5,\n",
    "    max_epochs = 300,\n",
    "    lr = 0.01,\n",
    "    optimizer = SGD,\n",
    "    optimizer__weight_decay = 0,\n",
    "    optimizer__momentum=0.9,\n",
    "    criterion = nn.BCELoss(),\n",
    "    batch_size=40,\n",
    "    # Turn the validation split off once we have the metadata values set\n",
    "    train_split = None,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__collate_fn=collate_data,\n",
    "    iterator_valid__collate_fn=collate_data,\n",
    "    # Turn off verbose\n",
    "    verbose = 0,\n",
    "    device='cuda',\n",
    ").initialize()\n",
    "net.load_params(f_params=f'trained_models/{current_attribute}/model.pkl',f_optimizer=f'trained_models/{current_attribute}/optimizer.pkl', f_history=f'trained_models/{current_attribute}/history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b005c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = net.predict_proba(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d071bcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Does       0.98      0.96      0.97      1150\n",
      "    Does Not       0.91      0.68      0.78       297\n",
      "\n",
      "   micro avg       0.97      0.90      0.94      1447\n",
      "   macro avg       0.95      0.82      0.88      1447\n",
      "weighted avg       0.97      0.90      0.93      1447\n",
      " samples avg       0.98      0.94      0.95      1447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Presence\n",
    "print(classification_report(test_dataset.labels_tensor > 0, y_proba > 0.5, labels=label_indices, target_names=target_names, zero_division='warn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "577754b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Does       0.50      0.66      0.57        65\n",
      "    Does Not       0.90      0.98      0.94       918\n",
      "\n",
      "   micro avg       0.87      0.96      0.91       983\n",
      "   macro avg       0.70      0.82      0.75       983\n",
      "weighted avg       0.88      0.96      0.92       983\n",
      " samples avg       0.78      0.78      0.78       983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Absence\n",
    "print(classification_report(test_dataset.labels_tensor < 1, y_proba <= 0.5, labels=label_indices, target_names=target_names, zero_division='warn'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
